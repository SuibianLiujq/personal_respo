#!/usr/bin/env python
# -*- coding:utf8 -*-
import sys, os
import requests,re,pickle, datetime
from lxml import etree, html
sys.path.append(os.path.pardir)
import blacklist_tools

def getParentUrl():
    url="http://mirror1.malwaredomains.com/files"
    http =requests.get(url=url)     #发送http请求
    neir = http.text                                      #获取http字符串代码
    tree = html.fromstring(neir)
    data = tree.xpath('//a/@href')
    return data

def malwaredomains():
    url="http://mirror1.malwaredomains.com/files/domains.txt"
    http =requests.get(url=url)     #发送http请求
    neir = http.text                                     #获取http字符串代码
    # print neir
    lines = neir.split('\r\n')
    del lines[0:4]
    data = []
    # print len(lines)
    # results = []
    for line in lines:
        result = re.findall("\d{8}\t{2}\w+", line)
        if len(result) >=1:
            lineSpr = line.split('\t\t')
            del lineSpr[0]
            for lineSprEle in lineSpr:
                cleanLineSprEle = lineSprEle.split('\t')
                # print cleanLineSprEle
                data.append(cleanLineSprEle)
            # print lineSpr
        else:
            temp = line.split('\t')
            del temp[0:2]
            data.append(temp)
    # for line in data:
    #     print line
    # print len(data)
    # print data[0]
    # print len(results)
    return data

def screen_data():
    web_set = ['private','spamhaus.org','isc.sans.edu','abuse.ch','techhelplist.com','malwaredomainlist.com','malwaredomains.com']
    results = malwaredomains()
    data = {}
    for temp in results:
        for domain in web_set:
            if re.search(domain,temp[2]):
                date =temp[3][0:4]+"-"+temp[3][4:6]+"-"+temp[3][6:8]
                data[temp[0]]={
                    'type':temp[1],
                    'date':date,
                    'source':temp[2],
                    'status':'unknown',
			        'fp':'unknown',
			        'level':'WARNING'
                }

    # print len(data)
    blacklist_tools.json_stdout(data)
    # return data

def store_data(date,data_dict,path):
    #用于存储全部信息
    file_name = path +str(date)+'.txt'
    fw1 = open(file_name,'wb')
    pickle.dump(data_dict, fw1, -1)
    fw1.close()



screen_data()
# store(screen_data())
# test()